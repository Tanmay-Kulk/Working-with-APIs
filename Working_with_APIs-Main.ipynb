{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355621ca-ff89-4777-9bc2-f518fe59b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if you have the below libraries if not use \"pip install\" syntax to install them\n",
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ec552-dfe2-4f83-8fd1-a9c7cefb1f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Api-Key.csv') # save your api key in a file of your choice which you access; I saved it in a csv file\n",
    "rapid_api_key = df.loc[df['API']== 'RapidApi']['KEY'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a7c7ae-822f-4244-a56a-dbb5e3a2ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://aerodatabox.p.rapidapi.com/flights/airports/iata/YYZ\" # here we have used API to get the data of Toronto Pearson Airpot(YYZ), \n",
    "                                                                     # you can also try codes from other airport and see what results you get!\n",
    "                                                                     # type the airport code after \"iata/<your airport code>\", in short just replace YYZ with desired airport code!\n",
    "\n",
    "querystring = {\"offsetMinutes\":\"-120\",\"durationMinutes\":\"720\",\"withLeg\":\"true\",\"direction\":\"Both\",\"withCancelled\":\"true\",\"withCodeshared\":\"true\",\"withCargo\":\"true\",\"withPrivate\":\"true\",\"withLocation\":\"false\"}\n",
    "\n",
    "headers = {\n",
    "\t\"x-rapidapi-key\": rapid_api_key, # place your api key here; PLEASE KEEP IN MIND API-KEY SHOULD BE ANONYMOUS and private\n",
    "\t\"x-rapidapi-host\": \"aerodatabox.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "new_response = response.json()\n",
    "print(response.status_code, '\\n') \n",
    "print(new_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5652c5-1196-480a-8ce8-0a8936c6f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "departures = new_response.get('departures', [])\n",
    "df = pd.json_normalize(departures)\n",
    "    \n",
    "# Cleaning up column names (making it more readable)\n",
    "df.columns = df.columns.str.replace('.', '_')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ddcc92-b9c8-417a-8b9f-3cfa96677b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--Data Info--','\\n')\n",
    "df.info()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31902be3-5ec0-4e0c-97f2-47e66a79f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--Data Shape--','\\n')\n",
    "print(f\" {df.shape[0]} rows, {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972aa69-1803-4d0f-98e2-063cb67e15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"{i+1}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6698aa0-2ee1-47bb-965c-20afe8c6a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1be5138-ffde-424e-aecc-6ea20415494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_info = df_copy.isnull().sum()\n",
    "missing_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa8ce2-b77f-4f43-bb1c-49018f0d1278",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = pd.DataFrame({\n",
    "        'Column': missing_info.index,\n",
    "        'Missing_Count': missing_info.values,\n",
    "    }).sort_values('Missing_Count', ascending=False)\n",
    "    \n",
    "print(\"Missing values by column:\")\n",
    "print(missing_df[missing_df['Missing_Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e608523a-4c98-4934-9610-43c7eddb9802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns with higher percentage of missing values\n",
    "\n",
    "threshold = 0.9 # here 0.9 indicates 90%, meaning those columns that have 90% of their data missing\n",
    "missing_percent = df.isnull().sum() / len(df)\n",
    "columns = missing_percent[missing_percent > threshold].index.tolist()\n",
    "\n",
    "print(f\"Dropping {len(columns)} columns with >{threshold*100}% missing values:\")\n",
    "for col in columns:\n",
    "    print(f\"  {col}: {missing_pct[col]:.1%} missing\")\n",
    "\n",
    "# creating another dataset which will be further used for exploratory analysis\n",
    "df_clean = df.drop(columns = columns)\n",
    "\n",
    "#Remaining columns\n",
    "print(f\"\\nRemaining columns: {df_clean.shape[1]}\")\n",
    "print(f\"Remaining rows: {df_clean.shape[0]}\")\n",
    "\n",
    "remaining_missing = df_clean.isnull().sum()\n",
    "print(\"\\nMissing values in remaining columns:\")\n",
    "print(remaining_missing[remaining_missing > 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e36da-773a-468a-9b51-a3cf842e9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting datetime columns\n",
    "datetime_columns = [col for col in df_clean.columns if 'Time' in col and 'utc' in col.lower()]\n",
    "for col in datetime_columns:\n",
    "    if col in df_clean.columns:\n",
    "        # Removing 'Z' suffix and converting them to datetime\n",
    "        df_clean[col] = pd.to_datetime(df_clean[col].str.replace('Z', ''), errors='coerce')\n",
    "        print(f\"Converted {col} to datetime\") # This print statement acts like a validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c411d8-974b-4fac-80e2-bd55d2611d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e15a2a-faae-4ab4-b691-bc8dea928812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating flight duration\n",
    "if 'departure_scheduledTime_utc' in df_clean.columns and 'arrival_scheduledTime_utc' in df_clean.columns:\n",
    "    df_clean['scheduled_duration_hours'] = round((\n",
    "    df_clean['arrival_scheduledTime_utc'] - df_clean['departure_scheduledTime_utc']\n",
    "    ).dt.total_seconds() / 3600, 2)\n",
    "    print(\"Added scheduled_duration_hours column to the dataframe.\")\n",
    "    \n",
    "# Calculating delays both for arrivals and departures\n",
    "if 'departure_revisedTime_utc' in df_clean.columns and 'departure_scheduledTime_utc' in df_clean.columns:\n",
    "    df_clean['departure_delay_minutes'] = abs((\n",
    "    df_clean['departure_revisedTime_utc'] - df_clean['departure_scheduledTime_utc']\n",
    "    ).dt.total_seconds() / 60) # using absolute function here to avoid negative values to keep things simple\n",
    "    print(\"Added departure_delay_minutes column to the dataframe.\")\n",
    "    \n",
    "if 'arrival_revisedTime_utc' in df_clean.columns and 'arrival_scheduledTime_utc' in df_clean.columns:\n",
    "    df_clean['arrival_delay_minutes'] = abs((\n",
    "    df_clean['arrival_revisedTime_utc'] - df_clean['arrival_scheduledTime_utc']\n",
    "    ).dt.total_seconds() / 60) # using absolute function here to avoid negative values to keep things simple\n",
    "    print(\"Added arrival_delay_minutes column to the dataframe.\")\n",
    "    \n",
    "# Extracting hour from departure time\n",
    "if 'departure_scheduledTime_utc' in df_clean.columns:\n",
    "    df_clean['departure_hour'] = df_clean['departure_scheduledTime_utc'].dt.hour\n",
    "    print(\"Added departure_hour column to the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169a7dd-3f6f-4dfb-b375-7063f92d0e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19496295-161d-4e0b-9a03-905ba769ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing some more columns\n",
    "df_clean = df_clean.drop(columns = ['arrival_baggageBelt'], errors = 'ignore')\n",
    "df_clean = df_clean.drop(columns = ['airline_icao'], errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27291212-81d3-4fc2-a13e-67ea97c495d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------ANALYSIS--------\n",
    "\n",
    "print('--Airline Analysis--', '\\n')\n",
    "if 'airline_name' in df_clean.columns:\n",
    "        # Top airlines by number of flights\n",
    "        airline_counts = df_clean['airline_name'].value_counts().head(10)\n",
    "        print(\"Top 10 Airlines by Number of Flights:\")\n",
    "        print(airline_counts)\n",
    "        \n",
    "# Airline performances\n",
    "if 'departure_delay_minutes' in df_clean.columns:\n",
    "    airline_performance = df_clean.groupby('airline_name').agg({\n",
    "    'departure_delay_minutes': ['mean', 'median', 'std', 'count']\n",
    "    }).round(2)\n",
    "            \n",
    "    airline_performance.columns = ['Avg_Delay', 'Median_Delay', 'Std_Delay', 'Flight_Count']\n",
    "    airline_performance = airline_performance.sort_values('Avg_Delay', ascending=False)\n",
    "            \n",
    "    print(\"\\nAirline Delay Performance (Top 10 by flight count):\")\n",
    "    top_airlines = airline_counts.head(10).index\n",
    "    print(airline_performance.loc[top_airlines])\n",
    "        \n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "airline_counts.plot(kind='bar')\n",
    "plt.title('Top 10 Airlines by Number of Flights')\n",
    "plt.xlabel('Airline')\n",
    "plt.ylabel('Number of Flights')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0277da11-fe52-43ff-9521-672ee01d7549",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- Delay Analysis --', '\\n')\n",
    "\n",
    "delay_columns = ['departure_delay_minutes', 'arrival_delay_minutes']\n",
    "available_delays = [col for col in delay_columns if col in df_clean.columns]\n",
    "    \n",
    "if available_delays:\n",
    "    for col in available_delays:\n",
    "        print(f\"\\n{col.replace('_', ' ').title()} Statistics:\")\n",
    "        delay_stats = df_clean[col].describe()\n",
    "        print(delay_stats)\n",
    "            \n",
    "        # Calculating on-time performance\n",
    "        on_time = (df_clean[col] <= 15).sum()  # Within 15 minutes is generally considered on-time\n",
    "        total = df_clean[col].notna().sum()\n",
    "        on_time_percent = (on_time / total) * 100\n",
    "        print(f\"On-time performances: {on_time_percent:.1f}%\")\n",
    "            \n",
    "        \n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        df_clean[col].hist(bins=50, alpha=0.7)\n",
    "        plt.title(f'{col.replace(\"_\", \" \").title()} Distribution')\n",
    "        plt.xlabel('Delay (minutes)')\n",
    "        plt.ylabel('Frequency')\n",
    "            \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b8f13-6d6e-49e8-9a0c-465fc30c0061",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-- Airport Analysis --\", '\\n')\n",
    "    \n",
    "if 'arrival_airport_name' in df_clean.columns:\n",
    "    # Top destination airports\n",
    "    airport_counts = df_clean['arrival_airport_name'].value_counts().head(10)\n",
    "    print(\"Top 10 Destination Airports:\")\n",
    "    print(airport_counts)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    airport_counts.plot(kind='bar')\n",
    "    plt.title('Top 10 Destination Airports')\n",
    "    plt.xlabel('Airport')\n",
    "    plt.ylabel('Number of Flights')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ad21b-091e-4f22-86ff-665a6306612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- Aircraft Model Analysis --')\n",
    "\n",
    "if 'aircraft_model' in df_clean.columns:\n",
    "    # Top aircraft models used\n",
    "    aircraft_counts = df_clean['aircraft_model'].value_counts().head(10)\n",
    "    print(\"Top 10 Aircraft Models:\")\n",
    "    print(aircraft_counts)\n",
    "        \n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    aircraft_counts.plot(kind='bar')\n",
    "    plt.title('Top 10 Aircraft Models')\n",
    "    plt.xlabel('Aircraft Model')\n",
    "    plt.ylabel('Number of Flights')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9450be-8349-404b-be0f-f1c686e22f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- Analysing Hourly Patterns --', '\\n')\n",
    "\n",
    "if 'departure_hour' in df_clean.columns:\n",
    "    # Departures by hour\n",
    "    hourly_flights = df_clean['departure_hour'].value_counts().sort_index()\n",
    "    print(\"Flights by Hour of Day:\")\n",
    "    print(hourly_flights)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    hourly_flights.plot(kind='line')\n",
    "    plt.title('Flight Departures by Hour of Day')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Number of Flights')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa724c9-5299-4290-93d5-1ed80a2b54c3",
   "metadata": {},
   "source": [
    "## Alternate Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d73ba21-95d7-496b-9b4c-4d1234eda3c9",
   "metadata": {},
   "source": [
    "#### If we only wanted to look at a particular section, say the arrivals section, then our code would have looked like this. Similarly, if we want to look at other sections we would follow the same steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7214a6e-f915-4eba-8edc-36fca230d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrivals_data(data):\n",
    "    \n",
    "    # First step, start by getting the departures list (this contains all flights)\n",
    "    departures = data.get('departures', [])\n",
    "    \n",
    "    # Second, extract only the arrival data from each flight by using get function\n",
    "    arrivals_list = []\n",
    "    for flight in departures:\n",
    "        arrival_data = flight.get('arrival', {})\n",
    "        if arrival_data:  # Only adds arrival data to the list if it exists\n",
    "            # Adding flight number for reference\n",
    "            arrival_data['flight_number'] = flight.get('number', '')\n",
    "            arrivals_list.append(arrival_data)\n",
    "    \n",
    "    # Lastly, converting the list to DataFrame using json_normalize\n",
    "    if arrivals_list:\n",
    "        df = pd.json_normalize(arrivals_list)\n",
    "        # Cleaning up column names\n",
    "        df.columns = df.columns.str.replace('.', '_')\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "arrivals_data(new_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
